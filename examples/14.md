
https://users.rust-lang.org/t/trait-impl-lifetime-nightmare/54735

https://gitlab.com/rafaelcout/rea/-/blob/devel/src/thi/lexer.rs



```rust
use std::iter::Peekable;
use std::str::Chars;

/// Rea code sources
pub enum Source {
    Code(&'static str),
}

/// Rea tokens
#[derive(Debug)]
pub enum Token {
    // Keywords
    Let,
    Print,

    // Data types
    Identifier(String),
    Integer(i64),
    Float(f64),
    StringLiteral(String),
    
    // Operators
    Assign,
    Plus,
    Minus,
    Multiply,
    Divide,

    // Delimiters
    Semicolon,
    LeftParenthesis,
    RightParenthesis,
}

/// Rea lexer trait
pub trait Lexer {
    /// New and usable lexer
    fn new(source: Source) -> Self;

    /// Is everything ok? true when usable
    fn ok(&mut self) -> bool;

    /// Next token
    fn next(&mut self) -> Option<Token>;
}

/// Rea lexer
pub struct ReaLexer<'chars> {
    chars: Option<Peekable<Chars<'chars>>>,
}

impl<'chars> Lexer for ReaLexer<'chars> {
    /// New and usable lexer
    fn new(source: Source) -> Self {
        let chars: &str = match source {
            Source::Code(code) => code,
        };

        ReaLexer {
            chars: Some(chars.chars().peekable()),
        }
    }

    /// Is everything ok? true when usable
    fn ok(&mut self) -> bool {
        if let Some(src) = &mut self.chars {
            src.peek().is_some()
        } else {
            false
        }
    }

    /// Next token
    fn next(&mut self) -> Option<Token> {
        if let Some(src) = &mut self.chars {
            while let Some(ch) = src.next() {
                if ch.is_whitespace() {
                    continue;
                }

                if ch.is_ascii_alphabetic() {
                    // Keywords or Identifiers
                    let mut word = String::new();
                    word.push(ch);

                    while let Some(&next_ch) = src.peek() {
                        if next_ch.is_ascii_alphanumeric() || next_ch == '_' {
                            word.push(src.next().unwrap());
                        } else {
                            break;
                        }
                    }

                    return match word.as_str() {
                        "let" => Some(Token::Let),
                        "print" => Some(Token::Print),
                        _ => Some(Token::Identifier(word)),
                    };
                }

                // Numeric literals
                if ch.is_ascii_digit() {
                    let mut num_str = String::new();
                    num_str.push(ch);

                    while let Some(&next_ch) = src.peek() {
                        if next_ch.is_ascii_digit() || next_ch == '.' {
                            num_str.push(src.next().unwrap());
                        } else {
                            break;
                        }
                    }

                    return if num_str.contains('.') {
                        Some(Token::Float(num_str.parse().unwrap()))
                    } else {
                        Some(Token::Integer(num_str.parse().unwrap()))
                    };
                }

                // String literals
                if ch == '\'' || ch == '\"' {
                    let mut string = String::new();

                    while let Some(next_ch) = src.next() {
                        if next_ch == ch {
                            break;
                        } else {
                            string.push(next_ch);
                        }
                    }

                    return Some(Token::StringLiteral(string));
                }

                // Operators and Delimiters
                return match ch {
                    '=' => Some(Token::Assign),
                    '+' => Some(Token::Plus),
                    '-' => Some(Token::Minus),
                    '*' => Some(Token::Multiply),
                    '/' => Some(Token::Divide),
                    ';' => Some(Token::Semicolon),
                    '(' => Some(Token::LeftParenthesis),
                    ')' => Some(Token::RightParenthesis),
                    _ => None,
                };
            }
        }

        None
    }
}

fn main() {
    let source_code = r#"
        let name = 'John Doe';
        let age = 30;
        let weight = 72.5;
        let description = "A person with some details: age and weight";
        let pi = 3.14159;
        let is_human = true;
        let fruits = ['apple', 'banana', 'orange'];
    "#;

    let mut lexer = ReaLexer::new(Source::Code(source_code));

    while lexer.ok() {
        if let Some(token) = lexer.next() {
            println!("{:?}", token);
        }
    }
}
```






The provided Rust code is a lexer implementation for a programming language called "Rea." A lexer is responsible for breaking the input source code into individual tokens that are meaningful units in the language. These tokens are then used by a parser to build an abstract syntax tree (AST) and further analyze and interpret the code.

Let's go through the code and understand the purpose of each component:

1. The `Source` enum: This enum defines a single variant called `Code`, which holds a reference to a static string (`&'static str`). The idea is to represent the input source code as a `Code` variant.

2. The `Token` enum: This enum defines different types of tokens that the lexer can produce. It covers various components of the Rea language, such as keywords (`Let`, `Print`), data types (`Identifier`, `Integer`, `Float`, `StringLiteral`), operators (`Assign`, `Plus`, `Minus`, `Multiply`, `Divide`), and delimiters (`Semicolon`, `LeftParenthesis`, `RightParenthesis`).

3. The `Lexer` trait: This trait defines an interface for a lexer with three methods:
   - `new`: Creates a new lexer from the provided `Source`.
   - `ok`: Checks if the lexer is in a usable state (i.e., if there are more characters to process).
   - `next`: Produces the next token from the input source code.

4. The `ReaLexer` struct: This is the implementation of the lexer for the Rea language. It holds an optional `Peekable<Chars>` iterator over characters from the input source code.

5. Implementation of the `Lexer` trait for `ReaLexer`: The methods `new`, `ok`, and `next` are implemented for the `ReaLexer` struct.

6. The `main` function: In the `main` function, a sample Rea source code is defined as a multi-line string (`source_code`). The `ReaLexer` is initialized with this source code, and then it iterates over the tokens produced by the lexer until there are no more tokens (`lexer.ok()`).

7. Tokenization: The `next` method of the `ReaLexer` implementation is the core of the lexer. It scans the input source code character by character and recognizes different tokens based on specific patterns. Here are the token recognition rules:
   - Keywords and Identifiers: Tokens starting with letters are treated as keywords or identifiers. Keywords are predefined (`let`, `print`), and other strings are considered identifiers.
   - Numeric Literals: Tokens starting with digits are treated as integer or floating-point literals.
   - String Literals: Tokens enclosed in single or double quotes are treated as string literals.
   - Operators and Delimiters: Recognizes various operators and delimiters by matching individual characters.

In summary, the purpose of this Rust code is to define a lexer for the Rea programming language. When provided with Rea source code, the lexer can break it down into a sequence of meaningful tokens, which can then be used for further processing, such as parsing and interpreting the code.












COMPILE!

PROTOTYPE

```rust
use std::iter::Peekable;
use std::str::Chars;

/// Rea code sources
pub enum Source {
    Code(&'static str),
}

/// Rea tokens
pub enum Token {
    Int,
    Float,
    String(String),
    Name(String),
    Assign,
    ParenthesesOpen,
    ParenthesesClose,
}

/// Rea lexer trait
pub trait Lexer {
    /// New and usable lexer
    fn new(source: Source) -> Self;

    /// Is everything ok? true when usable
    fn ok(&mut self) -> bool;

    /// Next token
    fn next(&mut self) -> Option<Token>;
}

/// Rea lexer
pub struct ReaLexer<'chars> {
    chars: Option<Peekable<Chars<'chars>>>,
}

impl<'chars> Lexer for ReaLexer<'chars> {
    /// New and usable lexer
    fn new(source: Source) -> Self {
        let chars: &str = match source {
            Source::Code(code) => code,
        };

        ReaLexer {
            chars: Some(chars.chars().peekable()),
        }
    }

    /// Is everything ok? true when usable
    fn ok(&mut self) -> bool {
        if self.chars.is_some() {
            return self.chars.as_mut().unwrap().peek().is_some();
        }

        false
    }

    /// Next token
    fn next(&mut self) -> Option<Token> {
        if self.chars.is_none() {
            return None;
        }

        let src = self.chars.as_mut().unwrap();

        let mut ch = match src.next() {
            Some(c) => c,
            None => return None,
        };

        // name
        if ch.is_ascii_alphabetic() {
            let mut name = String::new();

            loop {
                name.push(ch);
                ch = *src.peek().unwrap_or(&'0');

                if !ch.is_ascii_alphanumeric() {
                    break;
                }

                if ch == '0' {
                    break;
                }

                src.next();
            }

            print!(" name {}", name);
            return Some(Token::Name(name));
        }

        // =
        if ch == '=' {
            print!(" =");
            return Some(Token::Assign);
        }

        // 'string
        if ch == '\'' || ch == '\"' {
            let delim = ch;
            let mut string = String::new();

            loop {
                ch = src.next().unwrap_or('0');

                if ch == delim {
                    break;
                }

                if ch == '0' {
                    return None;
                }

                string.push(ch);
            }

            print!(" string {}", string);
            return Some(Token::String(string));
        }

        None
    }
}

fn main() {
    let source_code = r#"name = 'John Doe' "#; // Replace this with your input source

    let mut lexer = ReaLexer::new(Source::Code(source_code));
    let mut tokens: Vec<Token> = Vec::new();

    while lexer.ok() {
        if let Some(token) = lexer.next() {
            // Collect the tokens
            tokens.push(token);
        }
    }

    // Process the tokens as needed
    for token in &tokens {
        match token {
            Token::Int => println!("Integer"),
            Token::Float => println!("Float"),
            Token::String(s) => println!("String: {}", s),
            Token::Name(name) => println!("Name: {}", name),
            Token::Assign => println!("Assignment"),
            Token::ParenthesesOpen => println!("Open Parentheses"),
            Token::ParenthesesClose => println!("Close Parentheses"),
        }
    }
}
```